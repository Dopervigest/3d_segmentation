{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b45ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scripts import get_surface, get_sdf, scan\n",
    "#from scripts.models import Segmentation_Network_full as Segmentation_Network\n",
    "from scripts.utils import scale_to_unit_sphere, load_intra\n",
    "from scripts.sampling_cube import CubeSampler\n",
    "from scripts.dataset import CustomDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import namedtuple \n",
    "import os\n",
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0e77b-020e-41e6-a102-c5d6318d606d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ACDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17590ed9-d925-4bf0-b0c8-2ad15e4ddbd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'prepared_data/raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m test_names \u001b[38;5;241m=\u001b[39m names[split_idx:]\n\u001b[1;32m      8\u001b[0m dirrectory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprepared_data/raw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(dirrectory)\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'prepared_data/raw'"
     ]
    }
   ],
   "source": [
    "dir_in = './ACDC_simplified'#'./IntrA3D/obj'\n",
    "names = os.listdir(dir_in)\n",
    "split_idx = len(names)//2\n",
    "\n",
    "train_names = names[:split_idx]\n",
    "test_names = names[split_idx:]\n",
    "\n",
    "dirrectory = 'prepared_data/raw'\n",
    "os.mkdir(dirrectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09a33224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [54:37<00:00, 32.78s/it]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "\n",
    "for name in tqdm(names):\n",
    "    if os.path.exists(f'./{dirrectory}/{name[:-4]}'):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    train_dataset = CustomDataset(name,\n",
    "                                  device='cpu',\n",
    "                                  count=10,\n",
    "                                  rotate_angle=1,\n",
    "                                  dataset = 'acdc',\n",
    "                                  num_classes=num_classes)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, num_workers=16, shuffle=True)\n",
    "        \n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    count=0\n",
    "    for X, Y in (train_loader):\n",
    "        X = X.reshape([-1,1, 16,16,16])\n",
    "        Y = Y.reshape([-1, num_classes])\n",
    "\n",
    "        train_data.append(X)\n",
    "        train_labels.append(Y)\n",
    "        \n",
    "        count+=1\n",
    "        if count==40:\n",
    "            break\n",
    "        \n",
    "    new_train_data = torch.cat(train_data, dim=0)\n",
    "    new_train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "    os.mkdir(f'./{dirrectory}/{name[:-4]}')\n",
    "\n",
    "    torch.save(new_train_data, f'./{dirrectory}/{name[:-4]}/data.pt')\n",
    "    torch.save(new_train_labels, f'./{dirrectory}/{name[:-4]}/label.pt')\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e45763d1-e921-4e66-9cfa-e843360e1f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 1, 16, 16, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load('./prepared_data/raw/patient001/data.pt')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26db7d-06b8-45cb-bc2e-4a96ad308beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cdf508a-c4de-4745-95d1-96497855f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models for test dataset:  ['patient001', 'patient002', 'patient004', 'patient006', 'patient009', 'patient012', 'patient016', 'patient017', 'patient018', 'patient019', 'patient024', 'patient025', 'patient026', 'patient027', 'patient028', 'patient033', 'patient035', 'patient036', 'patient037', 'patient040', 'patient041', 'patient043', 'patient045', 'patient046', 'patient048', 'patient051', 'patient053', 'patient055', 'patient057', 'patient059', 'patient061', 'patient065', 'patient067', 'patient069', 'patient070', 'patient071', 'patient072', 'patient073', 'patient078', 'patient079', 'patient081', 'patient082', 'patient083', 'patient085', 'patient086', 'patient090', 'patient091', 'patient093', 'patient097', 'patient100']\n"
     ]
    }
   ],
   "source": [
    "datadir = './prepared_data/raw/'\n",
    "names = sorted(os.listdir(datadir))\n",
    "\n",
    "\n",
    "groups = []\n",
    "for i in range(1,100, 20):\n",
    "    groups.append(np.arange(i, i+20))\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "test_names = []\n",
    "for i in groups:\n",
    "    test_names.append(np.random.choice(i, 10, replace=False))\n",
    "test_names = list(np.concatenate(test_names))\n",
    "\n",
    "for i in range(len(test_names)):\n",
    "    name = test_names[i]\n",
    "    if len(str(name)) == 1:\n",
    "        test_names[i] = f'patient00{name}'\n",
    "    elif len(str(name)) == 2:\n",
    "        test_names[i] = f'patient0{name}'\n",
    "    else:\n",
    "        test_names[i] = f'patient{name}'\n",
    "print('Models for test dataset: ', sorted(test_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85cbb5e3-b305-436f-a7cf-2b0c2255fa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:08<00:00, 11.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([144918, 1, 16, 16, 16]),\n",
       " torch.Size([144867, 1, 16, 16, 16]),\n",
       " torch.Size([144918, 3]),\n",
       " torch.Size([144867, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for name in tqdm(names):\n",
    "    \n",
    "    data = torch.load(datadir+name+'/data.pt')\n",
    "    labels = torch.load(datadir+name+'/label.pt')\n",
    "\n",
    "    # equalizing the data\n",
    "    # takes N of indicies of each class equal to least populated group which is base \n",
    "    epi = (labels[:,0] == 1).nonzero().squeeze()\n",
    "    lv = (labels[:,1] == 1).nonzero().squeeze()\n",
    "    rv = (labels[:,2] == 1).nonzero().squeeze()\n",
    "\n",
    "    min_ = np.min([len(lv), len(rv), len(epi)])\n",
    " \n",
    "    epi = np.random.choice(epi, min_, replace=False)\n",
    "    lv = np.random.choice(lv, min_, replace=False)\n",
    "    rv = np.random.choice(rv, min_, replace=False)\n",
    "\n",
    "    if name in test_names:\n",
    "        test_data.append(data[lv])\n",
    "        test_labels.append(labels[lv])\n",
    "    \n",
    "        test_data.append(data[epi])\n",
    "        test_labels.append(labels[epi])\n",
    "        \n",
    "        test_data.append(data[rv])\n",
    "        test_labels.append(labels[rv])\n",
    "\n",
    "    else: \n",
    "        train_data.append(data[lv])\n",
    "        train_labels.append(labels[lv])\n",
    "    \n",
    "        train_data.append(data[epi])\n",
    "        train_labels.append(labels[epi])\n",
    "        \n",
    "        train_data.append(data[rv])\n",
    "        train_labels.append(labels[rv])\n",
    "        \n",
    "\n",
    "X_train = torch.concat(train_data, dim=0)\n",
    "X_test = torch.concat(test_data, dim=0)\n",
    "\n",
    "y_train = torch.concat(train_labels, dim=0)\n",
    "y_test = torch.concat(test_labels, dim=0)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49043945-73db-4b06-90b1-df4cb882bfe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './prepared_data/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dirr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./prepared_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './prepared_data/train'"
     ]
    }
   ],
   "source": [
    "dirr = './prepared_data/'\n",
    "os.makedirs(os.path.join(dirr, 'train'))\n",
    "os.makedirs(os.path.join(dirr, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224e1476-1a77-426d-a0db-5b2450fad87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.numpy()\n",
    "y_train = y_train.numpy()\n",
    "X_test = X_test.numpy()\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c2af836-cf24-476c-9e1f-c0c414cc760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File(os.path.join(dirr, 'train', 'data.hdf5'), 'w') as f:\n",
    "    f.create_dataset('points', data=X_train)\n",
    "    f.create_dataset('labels', data=y_train)\n",
    "\n",
    "\n",
    "with h5py.File(os.path.join(dirr, 'test', 'data.hdf5'), 'w') as f:\n",
    "    f.create_dataset('points', data=X_test)\n",
    "    f.create_dataset('labels', data=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1e8064-514c-481b-87c2-64860f3395fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.dataset import H5Dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "751d0626-daf2-49a3-8907-32db4c30c053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144918, 144867)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = H5Dataset('./prepared_data/train/data.hdf5')\n",
    "test_dataset = H5Dataset('./prepared_data/test/data.hdf5')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74feae04-a1f4-4773-9fa8-61482f607378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 16, 16, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad204f-1b96-4782-b5ec-276739adb84e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7317f8b4-19a3-446d-8147-83a93af9ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in = './data_for_transfer_learning/obj'#'./IntrA3D/obj'\n",
    "names = os.listdir(dir_in)\n",
    "split_idx = len(names)//2\n",
    "\n",
    "train_names = names[:split_idx]\n",
    "test_names = names[split_idx:]\n",
    "\n",
    "dirrectory = 'TL_prepared_data/raw'\n",
    "#os.mkdir(dirrectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8dc55d-e46d-4b4a-8be9-3b2073fc407b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7804fcb-69d4-4141-b225-5471d62ba0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 37/37 [29:33<00:00, 47.94s/it]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "\n",
    "for name in tqdm(names):\n",
    "    if os.path.exists(f'./{dirrectory}/{name[:-4]}'):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    train_dataset = CustomDataset(name,\n",
    "                                  device='cpu',\n",
    "                                  count=10,\n",
    "                                  rotate_angle=1,\n",
    "                                  dataset = 'clinical',\n",
    "                                  num_classes=num_classes,\n",
    "                                  data_dir=dir_in)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, num_workers=16, shuffle=True)\n",
    "        \n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    count=0\n",
    "    for X, Y in (train_loader):\n",
    "        X = X.reshape([-1,1, 16,16,16])\n",
    "        Y = Y.reshape([-1, num_classes])\n",
    "\n",
    "        train_data.append(X)\n",
    "        train_labels.append(Y)\n",
    "        \n",
    "        count+=1\n",
    "        if count==80:\n",
    "            break\n",
    "        \n",
    "    new_train_data = torch.cat(train_data, dim=0)\n",
    "    new_train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "    os.mkdir(f'./{dirrectory}/{name[:-4]}')\n",
    "\n",
    "    torch.save(new_train_data, f'./{dirrectory}/{name[:-4]}/data.pt')\n",
    "    torch.save(new_train_labels, f'./{dirrectory}/{name[:-4]}/label.pt')\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb9dd10-71db-4c1a-b095-2a91cf3c67bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.pt  label.pt\n"
     ]
    }
   ],
   "source": [
    "ls TL_prepared_data/raw/024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d335d5d4-4332-4fd2-8ef3-fb0aba962028",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('./TL_prepared_data/raw/019/data.pt')\n",
    "labels = torch.load('./TL_prepared_data/raw/019/label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3805c1df-9f67-4886-a112-a585fa47ffa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1868), tensor(4208), tensor(1162), tensor(762))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels[:,0] == 1), sum(labels[:,1] == 1), sum(labels[:,2] == 1), sum(labels[:,3] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6e886-4cc4-40fc-9c84-6a2da47b7ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3eb75-161f-425a-a2b8-3d8feecf1f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5970f1cd-7705-4c1a-840a-23123cdc9fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models for test dataset:  ['003', '009', '011', '012', '014', '016', '017', '021', '023', '026', '029', '030', '031', '032', '033', '034', '035', '037']\n"
     ]
    }
   ],
   "source": [
    "datadir = './TL_prepared_data/raw/'\n",
    "names = sorted(os.listdir(datadir))\n",
    "\n",
    "np.random.seed(0)\n",
    "test_names = np.random.choice(names, len(names)//2, replace=False)\n",
    "print('Models for test dataset: ', sorted(test_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c24474-43c8-434c-aa80-e7399f2be226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 37/37 [00:05<00:00,  6.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([46028, 1, 16, 16, 16]),\n",
       " torch.Size([43632, 1, 16, 16, 16]),\n",
       " torch.Size([46028, 4]),\n",
       " torch.Size([43632, 4]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for name in tqdm(names):\n",
    "    \n",
    "    data = torch.load(datadir+name+'/data.pt')\n",
    "    labels = torch.load(datadir+name+'/label.pt')\n",
    "\n",
    "    # equalizing the data\n",
    "    # takes N of indicies of each class equal to least populated group which is base \n",
    "    lv = (labels[:,0] == 1).nonzero().squeeze()\n",
    "    epi = (labels[:,1] == 1).nonzero().squeeze()\n",
    "    rv = (labels[:,2] == 1).nonzero().squeeze()\n",
    "    base = (labels[:,3] == 1).nonzero().squeeze()\n",
    "\n",
    "    lv = np.random.choice(lv, len(base), replace=False)\n",
    "    epi = np.random.choice(epi, len(base), replace=False)\n",
    "    rv = np.random.choice(rv, len(base), replace=False)\n",
    "\n",
    "\n",
    "    if name in test_names:\n",
    "        test_data.append(data[lv])\n",
    "        test_labels.append(labels[lv])\n",
    "    \n",
    "        test_data.append(data[epi])\n",
    "        test_labels.append(labels[epi])\n",
    "        \n",
    "        test_data.append(data[rv])\n",
    "        test_labels.append(labels[rv])\n",
    "        \n",
    "        test_data.append(data[base])\n",
    "        test_labels.append(labels[base])\n",
    "\n",
    "    else: \n",
    "        train_data.append(data[lv])\n",
    "        train_labels.append(labels[lv])\n",
    "    \n",
    "        train_data.append(data[epi])\n",
    "        train_labels.append(labels[epi])\n",
    "        \n",
    "        train_data.append(data[rv])\n",
    "        train_labels.append(labels[rv])\n",
    "        \n",
    "        train_data.append(data[base])\n",
    "        train_labels.append(labels[base])\n",
    "\n",
    "X_train = torch.concat(train_data, dim=0)\n",
    "X_test = torch.concat(test_data, dim=0)\n",
    "\n",
    "y_train = torch.concat(train_labels, dim=0)\n",
    "y_test = torch.concat(test_labels, dim=0)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99087658-847c-428b-9100-77ae807ad158",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './TL_prepared_data/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dirr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./TL_prepared_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './TL_prepared_data/train'"
     ]
    }
   ],
   "source": [
    "dirr = './TL_prepared_data/'\n",
    "os.makedirs(os.path.join(dirr, 'train'))\n",
    "os.makedirs(os.path.join(dirr, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defe3b34-8022-4f77-a5be-7ee5424be4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.numpy()\n",
    "y_train = y_train.numpy()\n",
    "X_test = X_test.numpy()\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50950f0-3962-479d-be4c-1d52adc5704d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7335016a-3bcb-4f2e-840f-46dbee9a6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(os.path.join(dirr, 'train', 'data.hdf5'), 'w') as f:\n",
    "    f.create_dataset('points', data=X_train)\n",
    "    f.create_dataset('labels', data=y_train)\n",
    "\n",
    "\n",
    "with h5py.File(os.path.join(dirr, 'test', 'data.hdf5'), 'w') as f:\n",
    "    f.create_dataset('points', data=X_test)\n",
    "    f.create_dataset('labels', data=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7732c-38a0-48d1-b4b1-1e292386d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.dataset import H5Dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a19aa56-2ae4-4e5a-b9cd-c53d061222f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = H5Dataset('./TL_prepared_data/train/data.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae3dd889-0a87-48cf-819f-9ad7d84d1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "becac9ce-af9c-4375-a2de-3d1b41a0a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
